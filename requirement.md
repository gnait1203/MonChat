# [프로그램 개발 지시서] 상품처리계 성능/오류 데이터 분석 Q&A 프로그램

## 1. 프로젝트 개요

- **목적**: 상품처리계의 성능 및 오류 데이터를 기반으로, 사용자가 자연어 질문을 통해 시스템의 상태를 분석하고 문제의 원인을 진단할 수 있는 Q&A 프로그램을 개발한다.
- **사용자**: 시스템 운영자 및 개발자
- **핵심 컨셉**: 분산된 여러 데이터 소스(RDBMS, 로그 파일)를 VectorDB로 통합하고, 사용자가 Streamlit 기반의 UI를 통해 손쉽게 데이터에 질문하고 시각화된 답변을 얻을 수 있는 환경을 구축한다.

---

## 2. 개발 범위 및 데이터 소스

본 프로그램은 **최근 1주일**의 데이터를 기준으로 분석을 수행한다.

1.  **상품처리계 오류 데이터**
    -   종류: Oracle RDBMS
    -   테이블: `event_history_YYYYMMDD`
    -   조회 방식: `SELECT * FROM event_history_YYYYMMDD`

2.  **상품처리계 성능 데이터**
    -   종류: Oracle RDBMS
    -   테이블: `history_YYYYMMDD`
    -   조회 방식: `SELECT * FROM history_YYYYMMDD`

3.  **미들웨어(WAS) 오류 데이터**
    -   종류: 서버 로그 파일
    -   경로: `/swlog/was/middleware_yyyymmdd`

4.  **데이터베이스(DB) 오류 데이터**
    -   종류: 서버 로그 파일
    -   경로: `/swlog/db/db_yyyymmdd`

---

## 3. 시스템 아키텍처

본 시스템은 **UI (Frontend)**, **API (Backend)**, **VectorDB** 세 가지 주요 파트로 구성된다.

![System Architecture Diagram](https://i.imgur.com/example.png)  -   **UI (Frontend)**
    -   **역할**: 사용자 Q&A 인터페이스, 데이터 시각화 대시보드
    -   **기술**: `Streamlit`
    -   **설명**: 사용자는 웹 UI를 통해 자연어로 질문을 입력하고, 분석 결과와 차트를 확인한다.

-   **API (Backend - MCP: Master Control Program)**
    -   **역할**: 데이터 수집/처리 제어, VectorDB 검색, UI 요청 처리
    -   **기술**: `FastAPI`
    -   **설명**: UI로부터 받은 요청을 처리하고, 질문을 벡터로 변환하여 VectorDB에서 유사 데이터를 검색한 후 결과를 반환한다. 또한, 주기적으로 데이터 소스로부터 데이터를 수집하고 VectorDB에 저장하는 파이프라인을 관리한다.

-   **VectorDB (Data Storage)**
    -   **역할**: 텍스트 데이터의 벡터 저장 및 유사도 검색
    -   **기술**: `pgvector` (PostgreSQL extension) on Docker
    -   **설명**: RDBMS와 로그 파일에서 수집된 정형/비정형 데이터를 임베딩 벡터로 변환하여 저장한다. 이를 통해 의미 기반의 빠른 데이터 검색이 가능하다.

---

## 4. 데이터 처리 흐름 (ETL Pipeline)

1.  **수집 (Extract)**: Python 스케줄러(예: APScheduler)를 사용하여 주기적으로 각 데이터 소스(Oracle, 로그 파일)에 접근하여 데이터를 가져온다.
2.  **변환 (Transform)**:
    -   가져온 원본 데이터를 의미 있는 단위(Chunk)로 분할하고 정제한다. (예: 로그 메시지 파싱, RDBMS row를 문장으로 변환)
    -   정제된 텍스트 데이터를 임베딩 모델(예: `ko-sbert-nli`)을 사용하여 고차원 벡터(Vector)로 변환한다.
3.  **적재 (Load)**:
    -   변환된 벡터와 원본 데이터, 메타데이터(출처, 시간 등)를 `pgvector`가 설치된 PostgreSQL DB에 저장한다.

---

## 5. 주요 개발 기능

### 가. Q&A 및 분석 기능

-   **자연어 질의 인터페이스**: 사용자가 "어제 가장 많이 발생한 에러 코드는 뭐야?" 와 같은 질문을 입력할 수 있는 채팅 형태의 입력창 구현.
-   **답변 생성**: 사용자 질문을 벡터로 변환하여 VectorDB에서 가장 유사한 데이터를 검색하고, 검색된 정보를 바탕으로 LLM(Language Model)을 활용하여 자연스러운 답변을 생성하여 제공.
-   **근거 데이터 제시**: 생성된 답변의 근거가 된 원본 데이터(로그 내용, DB row)를 함께 표시하여 사용자가 신뢰할 수 있도록 함.

### 나. 데이터 시각화 대시보드

-   **성능 지표 시각화**: `history` 테이블 데이터를 기반으로 시간별 트랜잭션 처리량(TPS), 평균 응답 시간 등을 라인 차트로 시각화.
-   **오류 트렌드 분석**: `event_history` 및 로그 데이터를 기반으로 오류 유형별 발생 빈도를 바(Bar) 차트, 파이(Pie) 차트 등으로 시각화.
-   **필터링 기능**: 특정 기간, 특정 오류 코드 등 사용자가 원하는 조건으로 데이터를 필터링하여 볼 수 있는 기능 제공.

### 다. 데이터 수집 및 관리

-   **배치(Batch) 실행 스크립트**: 지정된 데이터 소스에서 데이터를 수집, 변환, 적재하는 전체 파이프라인을 실행하는 Python 스크립트 개발.
-   **스케줄링**: 매일 새벽 특정 시간에 데이터 수집 파이프라인이 자동으로 실행되도록 스케줄링 기능 구현.

---

## 6. 개발 환경 및 필수 기술 스택

-   **공통**
    -   **언어**: Python 3.9 이상
    -   **형상 관리**: Git
-   **Backend (API)**
    -   **프레임워크**: FastAPI
    -   ** ASGI 서버**: Uvicorn
-   **Frontend (UI)**
    -   **프레임워크**: Streamlit
-   **Database**
    -   **VectorDB**: pgvector (PostgreSQL extension)
    -   **실행 환경**: Docker 컨테이너
-   **주요 Python 라이브러리**
    -   `fastapi`, `uvicorn`: API 서버 구축
    -   `streamlit`: UI 구축
    -   `psycopg2-binary`: PostgreSQL 연결
    -   `cx_Oracle`: Oracle DB 연결
    -   `pandas`: 데이터 처리 및 분석
    -   `langchain` 또는 `llama-index`: LLM 기반 애플리케이션 개발 프레임워크 (데이터 로딩, 임베딩, 검색 등)
    -   `sentence-transformers`: 텍스트 임베딩(벡터화)
    -   `apscheduler`: 데이터 수집 스케줄링

---

## 7. 최종 결과물

1.  **소스코드**: FastAPI, Streamlit, 데이터 처리 파이프라인 전체 Python 소스코드
2.  **의존성 파일**: `requirements.txt` (pip 패키지 목록)
3.  **컨테이너 설정 파일**: `docker-compose.yml` (pgvector 실행용)
4.  **실행 가이드**: `README.md` 파일 (프로젝트 설정, 실행 방법, API 엔드포인트 설명 포함)

---

## 8. 추가 고려사항

-   **보안**: DB 접속 정보 등 민감한 정보는 소스코드에 하드코딩하지 않고, 환경 변수나 별도의 설정 파일을 사용하여 관리한다.
-   **성능**: 대용량 로그 파일 처리 시 메모리 문제를 방지하기 위해 스트리밍 또는 청크 단위로 파일을 읽어 처리하도록 구현한다.
-   **확장성**: 향후 새로운 데이터 소스(예: Elasticsearch, 다른 로그 파일)가 추가될 경우를 대비하여 데이터 수집 로직을 모듈화하여 설계한다.
-   **예외 처리**: 데이터베이스 연결 실패, 파일 경로 없음 등 데이터 처리 과정에서 발생할 수 있는 다양한 예외 상황에 대한 처리 로직을 반드시 포함한다.